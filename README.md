# ğŸ“Œ **Misbehavior detection in VANET using Deep Learning**

This project implements a complete deep learningâ€“based misbehavior detection pipeline for the VEREMI dataset, used in VANET (Vehicular Ad Hoc Network) security analysis.
The system uses neural networks â€” MLP and CNN-1D â€” along with an additional XGBoost baseline model for comparison.

Advanced interpretability methods such as SHAP and LIME are used to provide Explainable AI (XAI) insights into how the deep learning models make decisions.

---

## ğŸš€ **Project Highlights**

* Full preprocessing pipeline
  âœ” Data Cleaning
  âœ” Data Normalization
  âœ” Data Transformation
* Parallel training of three models:

  * **MLP**
  * **CNN-1D**
  * **XGBoost**
* Evaluation Metrics:

  * Accuracy
  * 
  * Confusion Matrix
  * ROC Curve
  
* Explainability (XAI):

  * SHAP Summary Plots
  * LIME Instance-Level Explanations
* All results automatically saved to the `/results` directory

---

## ğŸ“‚ **Project Structure**

```
Capstone-147/
â”œâ”€â”€ main.py
â”œâ”€â”€ main_improved.py
â”œâ”€â”€ npz.py
â”œâ”€â”€ npz_reduce.py
â”œâ”€â”€ train_raw_models.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ explainability/
â”‚   â”œâ”€â”€ models_raw/
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ confusion_matrices/
â”‚   â”œâ”€â”€ shap_output/
â”‚
â””â”€â”€ README.md
```

---

## ğŸ“Š **Dataset: VEREMI**

The **VEREMI dataset** is a well-known benchmark for detecting malicious behavior in Vehicular Ad Hoc Networks (VANETs).
It contains labeled entries:

* **0 â†’ Legitimate node**
* **1 â†’ Misbehaving node**

Large `.csv` files are converted into efficient `.npz` format using:

```
python npz.py
```

Dataset files are **excluded from GitHub using `.gitignore`**.

---

## ğŸ› ï¸ **Installation**

### 1ï¸âƒ£ Create a Conda environment

```bash
conda create -n vanet python=3.10
conda activate vanet
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

Install XGBoost (if not included):

```bash
pip install xgboost
```

---

## ğŸ§¹ **Data Preprocessing**

Preprocessing includes:

* Removing invalid entries
* Normalizing features
* Transforming dataset into trainable format

Generate `.npz`:

```
python npz.py
```

---

## ğŸ¤– **Training the Models**

### **Train MLP + CNN-1D (Raw Models)**

```
python main.py --cache_npz veremi_binary_1m.npz --epochs 20 --batch_size 512
```

### **Train XGBoost**

```
python main_improved.py --model xgb --cache_npz veremi_binary_1m.npz
```

All outputs are saved to:

```
results/
```

---

## ğŸ“ˆ **Evaluation Metrics**

For each model, the following are generated:

* Accuracy score
* Macro F1 & Weighted F1
* Precision/Recall
* Confusion Matrix (PNG)
* ROC Curve (PNG)
* sklearn classification report

Example files:

```
results/confusion_matrices/mlp_cm.png
results/confusion_matrices/cnn1d_cm.png
results/confusion_matrices/xgb_cm.png
```

---

## ğŸ§  **Explainability (XAI)**

### SHAP

Generates global feature importance using SHAP values:

```
python explain_raw_models.py
```

### LIME

Explains predictions for a specific test instance:

```
python run_lime.py
```

Output files include:

* `shap_mlp.png`
* `lime_output.png`

---

## ğŸ§© **System Architecture Overview**

The architecture includes:

* Dataset ingestion
* Preprocessing
* Parallel training of MLP, CNN-1D, XGBoost
* Unified evaluation pipeline
* Explainability layer (SHAP + LIME)

(Architecture diagram included separately in repo.)

---

## âš™ï¸ **Tech Stack**

| Component      | Technology                           |
| -------------- | ------------------------------------ |
| Language       | Python 3.10                          |
| ML Frameworks  | TensorFlow, XGBoost                  |
| Explainability | SHAP, LIME                           |
| Visualization  | Matplotlib, Seaborn                  |
| Environment    | Conda                                |
| Dataset        | VEREMI (VANET Misbehavior Detection) |

---

## ğŸ§ª **Results Summary**

| Model   | Accuracy (Approx.) | Notes                 |
| ------- | ------------------ | --------------------- |
| MLP     | ~52â€“53%            | Balanced baseline     |
| CNN-1D  | ~52â€“53%            | Similar to MLP        |
| XGBoost | ~58%               | Best performing model |

---

## ğŸ‘¨â€ğŸ’» **Developed By**

**Nabirasul A**
B.Tech â€“ Computer Science Engineering
Capstone Project 147

---

## ğŸ“„ **License**

This repository is for **academic and research use only**.

---

If you want, I can also provide:

âœ” Enhanced GitHub banner
âœ” Shields badges (Python version, last commit, stars)
âœ” A better architecture diagram (HD horizontal)
âœ” A professional project PDF for submission

Just tell me!

